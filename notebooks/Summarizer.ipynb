{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5050c696",
   "metadata": {},
   "source": [
    "**SUMMARIZER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919eef3",
   "metadata": {},
   "source": [
    "In this notebook we will develop the summarizing functions for a production setting.\n",
    "<br>\n",
    "In dev we tried the following models:\n",
    "1. BART-LARGE-CNN\n",
    "2. DeepSeek-Qwen-R1\n",
    "3. PEGASUS\n",
    "4. flan-t5-large\n",
    "<br>\n",
    "\n",
    "We concluded that the best one to use would be flan-t5-large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739cba2",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7378e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "from credentials import Credentials\n",
    "credentials = Credentials()\n",
    "os.environ[\"http_proxy\"] = credentials.http_proxy\n",
    "os.environ[\"https_proxy\"] = credentials.https_proxy\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d27bbed",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msummarizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\A200348545\\Escritorio 2\\Personal-Projects\\BannerG\\PRO\\notebooks\\..\\functions\\summarizer.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\A200348545\\AppData\\Local\\anaconda3\\envs\\bannerg\\Lib\\site-packages\\transformers\\__init__.py:950\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m    948\u001b[39m _import_structure = {k: \u001b[38;5;28mset\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _import_structure.items()}\n\u001b[32m--> \u001b[39m\u001b[32m950\u001b[39m import_structure = \u001b[43mdefine_import_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    951\u001b[39m import_structure[\u001b[38;5;28mfrozenset\u001b[39m({})].update(_import_structure)\n\u001b[32m    953\u001b[39m sys.modules[\u001b[34m__name__\u001b[39m] = _LazyModule(\n\u001b[32m    954\u001b[39m     \u001b[34m__name__\u001b[39m,\n\u001b[32m    955\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[33m\"\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    958\u001b[39m     extra_objects={\u001b[33m\"\u001b[39m\u001b[33m__version__\u001b[39m\u001b[33m\"\u001b[39m: __version__},\n\u001b[32m    959\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\A200348545\\AppData\\Local\\anaconda3\\envs\\bannerg\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2851\u001b[39m, in \u001b[36mdefine_import_structure\u001b[39m\u001b[34m(module_path, prefix)\u001b[39m\n\u001b[32m   2827\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[32m   2828\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefine_import_structure\u001b[39m(module_path: \u001b[38;5;28mstr\u001b[39m, prefix: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> IMPORT_STRUCTURE_T:\n\u001b[32m   2829\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2830\u001b[39m \u001b[33;03m    This method takes a module_path as input and creates an import structure digestible by a _LazyModule.\u001b[39;00m\n\u001b[32m   2831\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2849\u001b[39m \u001b[33;03m    If `prefix` is not None, it will add that prefix to all keys in the returned dict.\u001b[39;00m\n\u001b[32m   2850\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2851\u001b[39m     import_structure = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2852\u001b[39m     spread_dict = spread_import_structure(import_structure)\n\u001b[32m   2854\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\A200348545\\AppData\\Local\\anaconda3\\envs\\bannerg\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2564\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(module_path):\n\u001b[32m   2563\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f != \u001b[33m\"\u001b[39m\u001b[33m__pycache__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m os.path.isdir(os.path.join(module_path, f)):\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m         import_structure[f] = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2566\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(os.path.join(directory, f)):\n\u001b[32m   2567\u001b[39m         adjacent_modules.append(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\A200348545\\AppData\\Local\\anaconda3\\envs\\bannerg\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2588\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2585\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_name.endswith(\u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2586\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2588\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   2589\u001b[39m     file_content = f.read()\n\u001b[32m   2591\u001b[39m \u001b[38;5;66;03m# Remove the .py suffix\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:309\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, errors)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from functions.summarizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b8782",
   "metadata": {},
   "source": [
    "# 1. Google flan-t5-large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe60b4",
   "metadata": {},
   "source": [
    "Loading the models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29103b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c79afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8b6d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cec6a9",
   "metadata": {},
   "source": [
    "Loading the dictionary of images info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b8d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_dict(images_dict_path:str)->dict:\n",
    "    \"\"\"Loads images dictionary from the path\n",
    "\n",
    "    Args:\n",
    "        images_dict_path (str): Path to images dictionary\n",
    "\n",
    "    Returns:\n",
    "        dict: Images dictionary\n",
    "    \"\"\"\n",
    "    with open(images_dict_path, 'rb') as fp:\n",
    "        images_dict = pickle.load(fp)\n",
    "    return images_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8572ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dict = load_images_dict('images_dict.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e8a699",
   "metadata": {},
   "source": [
    "Generating a random prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84f6028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_prompt(images_dict: dict)->str:\n",
    "    \"\"\"Generates a prompt from the images dictionary by combining three random elements \n",
    "\n",
    "    Args:\n",
    "        images_dict (dict): Images dictionary\n",
    "\n",
    "    Returns:\n",
    "        str: Generated prompt\n",
    "    \"\"\"\n",
    "    #choosing three random elements\n",
    "    keys = list(images_dict.keys()) \n",
    "    chosen_keys = [str(string) for string in np.random.choice(keys, 3, replace=False)] \n",
    "    print(chosen_keys)\n",
    "\n",
    "    #building the prompt\n",
    "    prompt = images_dict[chosen_keys[0]]['person']\n",
    "    prompt += images_dict[chosen_keys[1]]['clothes']\n",
    "    prompt += images_dict[chosen_keys[2]]['scenario']\n",
    "    print(f\"Final prompt (length: {len(prompt.split(\" \"))}): {prompt}\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b8c80ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['polo2.jpg', 'trench.png', 'beach.jpg']\n",
      "Final prompt (length: 99): The image features a person who appears to be a young adult male. He has short, light-colored hair and is wearing glasses.The person is wearing a long, oversized coat that reaches down to her ankles. The coat has a high collar and appears to be made of a heavy fabric, suggesting a fashion style that is both functional and fashionable.The scene is set outdoors, with a basketball hoop in the background. The person is posing in front of the hoop, with her hands on her hips and her head turned to the side, giving a confident and stylish appearance.\n"
     ]
    }
   ],
   "source": [
    "prompt = generate_random_prompt(images_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3ef989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flan_t5_summarize(prompt, context):\n",
    "    \"\"\"Summarizes a text into about half his size given a context\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Prompt to summarize.\n",
    "        context (str): Context of the prompt (person, scenario, image...)\n",
    "\n",
    "    Returns:\n",
    "        str: Summarized prompt.\n",
    "    \"\"\"\n",
    "    prompt_length = len(prompt.split(\" \"))\n",
    "    final_prompt_1 = f'Summarize this {context} comprehensively into {prompt_length//2} tokens \"' + prompt + '\"'\n",
    "    print(final_prompt_1)\n",
    "    target_tokens = prompt_length//2\n",
    "    min_tokens = target_tokens - 15\n",
    "    max_tokens = target_tokens + 15\n",
    "    print(f\"Prompt_length: {prompt_length}, target_length: {target_tokens}, max_output: {max_tokens}, min_output: {min_tokens}\")\n",
    "\n",
    "    # First summarization \n",
    "    summparams = SummParams(\n",
    "        text = final_prompt_1,\n",
    "        tokenizer = tokenizer,\n",
    "        model = model,\n",
    "        num_beams = 6,\n",
    "        max_input_length = 1024,\n",
    "        min_output_length = max(16, min_tokens),\n",
    "        max_output_length= max_tokens,\n",
    "        device = device\n",
    "    )\n",
    "    summarized_text_1 = summarize_text(summparams)\n",
    "    return summarized_text_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907d57b",
   "metadata": {},
   "source": [
    "Trying it with three random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9d5d21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trench.png', 'polo.jpg', 'dior.png']\n",
      "Summarize this person comprehensively into 15 tokens \"The image features a person who appears to be a woman. She has a fair complexion and her hair is styled in a way that it falls over her shoulders.\"\n",
      "Prompt_length: 30, target_length: 15, max_output: 30, min_output: 0\n",
      "Final prompt (length: 23): The image features a person who appears to be a woman. She has a fair complexion and her hair is styled in a\n",
      "\n",
      "Summarize this clothes comprehensively into 19 tokens \"The person is wearing a long, oversized coat that reaches down to her ankles. The coat has a high collar and appears to be made of a heavy fabric, suggesting a fashion style that is both functional and fashionable.\"\n",
      "Prompt_length: 39, target_length: 19, max_output: 34, min_output: 4\n",
      "Final prompt (length: 14): The person is wearing a long, oversized coat that reaches down to her ankles.\n",
      "\n",
      "Summarize this scenario comprehensively into 38 tokens \"The scene is set against a plain, light-colored background that provides a neutral backdrop for the person. The person is posing in a way that she is looking directly at the camera, with her head slightly tilted to one side. Her pose is elegant and poised, with her hands resting at her sides. The overall composition of the image suggests a focus on the coat and the person's style, with the background serving to highlight the clothing.\"\n",
      "Prompt_length: 77, target_length: 38, max_output: 53, min_output: 23\n",
      "Final prompt (length: 36): Set the scene against a plain, light-colored background that provides a neutral backdrop for the person. Pose in a way that she is looking directly at the camera with her head slightly tilted to one side.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#choosing three random elements\n",
    "keys = list(images_dict.keys()) \n",
    "chosen_keys = [str(string) for string in np.random.choice(keys, 3, replace=False)] \n",
    "print(chosen_keys)\n",
    "\n",
    "#building the prompt\n",
    "elements = ['person', 'clothes', 'scenario']\n",
    "for element in elements:\n",
    "    prompt = images_dict[chosen_keys[0]][element]\n",
    "    prompt_length = len(prompt.split(\" \"))\n",
    "    #print(prompt_length)\n",
    "    if prompt_length>20:\n",
    "        summary = flan_t5_summarize(prompt, element)\n",
    "        print(f\"Final prompt (length: {len(summary.split(\" \"))}): {summary}\\n\")\n",
    "    else:\n",
    "        print(f\"Final prompt (length: {prompt_length}): {prompt}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59566266",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98aba1",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf03467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b603652",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = 'Summarize into: person description, clothing, pose, background\". Text: \"' + prompt + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4854bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt =  'Summarize this text. Text: \"The scene takes place in a room with orange walls, which complements the persons outfit. The person is sitting on a large, round, orange cushion or ottoman, which is placed against the wall. She is posing in a relaxed manner, with one leg crossed over the other, and her hands resting on her knees. The persons pose and the choice of the orange background create a cohesive and visually appealing image that highlights the clothing and the color scheme.\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8dd6fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summarize this text. Text: \"The scene takes place in a room with orange walls, which complements the persons outfit. The person is sitting on a large, round, orange cushion or ottoman, which is placed against the wall. She is posing in a relaxed manner, with one leg crossed over the other, and her hands resting on her knees. The persons pose and the choice of the orange background create a cohesive and visually appealing image that highlights the clothing and the color scheme.\"'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f034eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summparams = SummParams(\n",
    "    text = final_prompt,\n",
    "    tokenizer = tokenizer,\n",
    "    model = model,\n",
    "    num_beams = 6,\n",
    "    max_input_length = 1024,\n",
    "    min_output_length = 80,\n",
    "    max_output_length= 110,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31bde7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The image features a person who appears to be a woman. She has a fair complexion and her hair is styled in a way that it falls over her shoulders. The person is wearing a bright orange hoodie and matching orange socks. Her fashion style can be described as casual and sporty, with a focus on bold, vibrant colors. The scene takes place in a room with a brick wall in the background.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_text = summarize_text(summparams)\n",
    "summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "01507fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summarized_text.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc18d0b",
   "metadata": {},
   "source": [
    "Resummarizing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f395a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = 'Summarize into about 77 tokens, including: person description, clothing, pose, background. Text: \"' + summarized_text + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "578085bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summarize into about 77 tokens, including: person description, clothing, pose, background. Text: \"The image features a male model with short hair and appears to be of African descent. The person is dressed in a suit and tie, with a pink shirt and a blue blazer. The scene is set on a city street, with a window and a street sign in the background. The person is standing on the sidewalk, posing with one hand on her hip and the other hand resting on her thigh.\"'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "43308210",
   "metadata": {},
   "outputs": [],
   "source": [
    "summparams = SummParams(\n",
    "    text = final_prompt,\n",
    "    tokenizer = tokenizer,\n",
    "    model = model,\n",
    "    num_beams = 6, \n",
    "    max_input_length = 1024,\n",
    "    min_output_length = 60,\n",
    "    max_output_length= 77,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fdf8a7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image features a male model with short hair and appears to be of African descent. The person is dressed in a suit and tie, with a pink shirt and a blue blazer. The scene is set on a city street, with a window and a street sign in the background'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_text_2 = summarize_text(summparams)\n",
    "summarized_text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bfdfccd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summarized_text_2.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d3e6d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_prompt(prompt: str, tokenizer, model, device) ->str:\n",
    "    \"\"\"Summarizes the generated prompt using BART-LARGE-CNN three times (sequentially), so that it fits into 77 tokens (approx 55 words).\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Generated prompt.\n",
    "        tokenizer: Tokenizer.\n",
    "        model: Model.\n",
    "        device: Device.\n",
    "\n",
    "    Returns:\n",
    "        str: Prompt summarized into 77 tokens (55 words)\n",
    "    \"\"\"\n",
    "    final_prompt_1 = 'Summarize into: person description, clothing, pose, background\". Text: \"' + prompt + '\"'\n",
    "    # First summarization \n",
    "    summparams = SummParams(\n",
    "        text = final_prompt_1,\n",
    "        tokenizer = tokenizer,\n",
    "        model = model,\n",
    "        num_beams = 6,\n",
    "        max_input_length = 1024,\n",
    "        min_output_length = 80,\n",
    "        max_output_length= 110,\n",
    "        device = device\n",
    "    )\n",
    "    summarized_text_1 = summarize_text(summparams)\n",
    "    print(f\"Summary 1 (length: {len(summarized_text_1.split(\" \"))}): {summarized_text_1}\")\n",
    "\n",
    "    # Second summarization\n",
    "    final_prompt_2 = 'Summarize into 77 tokens, including: person description, clothing, pose, background. Text: \"' + summarized_text_1 + '\"'\n",
    "    summparams.text = final_prompt_2\n",
    "    summparams.num_beams = 6\n",
    "    summparams.max_input_length = 1024\n",
    "    summparams.min_output_length = 60\n",
    "    summparams.max_output_length = 77\n",
    "    summarized_text_2 = summarize_text(summparams)\n",
    "    print(f\"Summary 2 (length: {len(summarized_text_2.split(\" \"))}): {summarized_text_2}\")\n",
    "\n",
    "    return summarized_text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d2c42d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gucci.jpg', 'trench.png', 'loewe.jpg']\n",
      "Final prompt (length: 136): The image features a person who appears to be a woman. She has dark skin and is wearing her hair in an updo.The person is wearing a long, oversized coat that reaches down to her ankles. The coat has a high collar and appears to be made of a heavy fabric, suggesting a fashion style that is both functional and fashionable.The scene is set against a white brick wall with a decorative element that resembles a heart shape. The model is posing on a stool, sitting with one leg crossed over the other, and holding the bag in his lap. He is looking directly at the camera with a neutral expression. The overall fashion style of the image suggests a casual yet stylish look, possibly for a brand that focuses on leather accessories and casual outerwear.\n",
      "Summary 1 (length: 85): The image features a person who appears to be a woman. She has dark skin and is wearing her hair in an updo. The person is wearing a long, oversized coat that reaches down to her ankles. The scene is set against a white brick wall with a decorative element resembles a heart shape. The model is posing on a stool, sitting with one leg crossed over the other, and holding the bag in his lap. The overall fashion style of the image suggests \n",
      "Summary 2 (length: 54): The image features a person who appears to be a woman. She has dark skin and is wearing her hair in an updo. The person is wearing a long, oversized coat that reaches down to her ankles. The scene is set against a white brick wall with a decorative element resembles a heart shape.\n"
     ]
    }
   ],
   "source": [
    "prompt = generate_random_prompt(images_dict)\n",
    "s = summarize_prompt(prompt, tokenizer, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c370fdf",
   "metadata": {},
   "source": [
    "## pruebas (resumir por separado y luego juntar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21bc6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prueba_summarize(prompt):\n",
    "    prompt_length = len(prompt.split(\" \"))\n",
    "    final_prompt_1 = f'Summarize into {prompt_length//2} tokens \"' + prompt + '\"'\n",
    "    final_prompt_2 = f'Summarize this description comprehensively into {prompt_length//2} tokens \"' + prompt + '\"'\n",
    "    print(final_prompt_1)\n",
    "    target_tokens = prompt_length//2\n",
    "    min_tokens = target_tokens - 15\n",
    "    max_tokens = target_tokens + 15\n",
    "    print(f\"Prompt_length: {prompt_length}, target_length: {target_tokens}, max_output: {max_tokens}, min_output: {min_tokens}\")\n",
    "\n",
    "    # First summarization \n",
    "    summparams = SummParams(\n",
    "        text = final_prompt_1,\n",
    "        tokenizer = tokenizer,\n",
    "        model = model,\n",
    "        num_beams = 6,\n",
    "        max_input_length = 1024,\n",
    "        min_output_length = max(16, min_tokens),\n",
    "        max_output_length= max_tokens,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "    # summarize with prompt_1\n",
    "    summarized_text_1 = summarize_text(summparams)\n",
    "    if summarized_text_1[-1]=='.':\n",
    "        return summarized_text_1\n",
    "\n",
    "    else:\n",
    "        # summarize with prompt_2\n",
    "        summparams.text = final_prompt_2\n",
    "        summarized_text_2 = summarize_text(summparams)\n",
    "        return summarized_text_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7463f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prueba_summarize(prompt, context):\n",
    "    \"\"\"Summarizes a text into about half his size given a context\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Prompt to summarize.\n",
    "        context (str): Context of the prompt (person, scenario, image...)\n",
    "\n",
    "    Returns:\n",
    "        str: Summarized prompt.\n",
    "    \"\"\"\n",
    "    prompt_length = len(prompt.split(\" \"))\n",
    "    final_prompt_1 = f'Summarize this {context} comprehensively into {prompt_length//2} tokens \"' + prompt + '\"'\n",
    "    print(final_prompt_1)\n",
    "    target_tokens = prompt_length//2\n",
    "    min_tokens = target_tokens - 15\n",
    "    max_tokens = target_tokens + 15\n",
    "    print(f\"Prompt_length: {prompt_length}, target_length: {target_tokens}, max_output: {max_tokens}, min_output: {min_tokens}\")\n",
    "\n",
    "    # First summarization \n",
    "    summparams = SummParams(\n",
    "        text = final_prompt_1,\n",
    "        tokenizer = tokenizer,\n",
    "        model = model,\n",
    "        num_beams = 6,\n",
    "        max_input_length = 1024,\n",
    "        min_output_length = max(16, min_tokens),\n",
    "        max_output_length= max_tokens,\n",
    "        device = device\n",
    "    )\n",
    "    summarized_text_1 = summarize_text(summparams)\n",
    "    return summarized_text_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b52dd236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beach.jpg', 'trench.png', 'loewe.jpg']\n",
      "Summarize this person comprehensively into 15 tokens \"The image features a person who appears to be a woman. She has dark hair, and her skin tone is light. She is wearing a yellow hoodie and yellow sweatpants.\"\n",
      "Prompt_length: 30, target_length: 15, max_output: 30, min_output: 0\n",
      "Final prompt (length: 17): The image features a person who appears to be a woman with dark hair and light skin.\n",
      "\n",
      "Final prompt (length: 17): The person is wearing a casual, sporty fashion style, characterized by the matching yellow hoodie and sweatpants.\n",
      "\n",
      "Summarize this scenario comprehensively into 20 tokens \"The scene is set outdoors, with a basketball hoop in the background. The person is posing in front of the hoop, with her hands on her hips and her head turned to the side, giving a confident and stylish appearance.\"\n",
      "Prompt_length: 40, target_length: 20, max_output: 35, min_output: 5\n",
      "Final prompt (length: 10): A person is posing in front of a basketball hoop.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#choosing three random elements\n",
    "keys = list(images_dict.keys()) \n",
    "chosen_keys = [str(string) for string in np.random.choice(keys, 3, replace=False)] \n",
    "print(chosen_keys)\n",
    "\n",
    "#building the prompt\n",
    "elements = ['person', 'clothes', 'scenario']\n",
    "for element in elements:\n",
    "    prompt = images_dict[chosen_keys[0]][element]\n",
    "    prompt_length = len(prompt.split(\" \"))\n",
    "    #print(prompt_length)\n",
    "    if prompt_length>20:\n",
    "        summary = prueba_summarize(prompt, element)\n",
    "        print(f\"Final prompt (length: {len(summary.split(\" \"))}): {summary}\\n\")\n",
    "    else:\n",
    "        print(f\"Final prompt (length: {prompt_length}): {prompt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5be2a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(summparams: SummParams) -> str:\n",
    "    \"\"\"Summarizes text\n",
    "\n",
    "    Args:\n",
    "        summparams (SummParams): Parameters for text summarization (dataclass)\n",
    "\n",
    "    Returns:\n",
    "        str: Summarized text\n",
    "    \"\"\"\n",
    "    inputs = summparams.tokenizer([summparams.text], max_length=summparams.max_input_length, return_tensors='pt').to(summparams.device)\n",
    "    summary_ids = summparams.model.generate(inputs['input_ids'], num_beams=summparams.num_beams, min_length=summparams.min_output_length, max_length=summparams.max_output_length, early_stopping=True)\n",
    "    return (summparams.tokenizer.decode(summary_ids[0], skip_special_tokens=True, truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3f56660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize this person comprehensively into 15 tokens \"The person is wearing a bright orange dress. The fashion style of the person can be described as summery and vibrant, with a focus on bold colors and light fabrics.\"\n",
      "The person is wearing a bright orange dress. The fashion style of the person can be described as summery and\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#prompt = \"The scene takes place in a room with orange walls, which complements the person's outfit. The person is sitting on a large, round, orange cushion or ottoman, which is placed against the wall. She is posing in a relaxed manner, with one leg crossed over the other, and her hands resting on her knees. The person's pose and the choice of the orange background create a cohesive and visually appealing image that highlights the clothing and the color scheme.\"\n",
    "#prompt = \"The image features a person who appears to be a woman. She has light skin and is wearing makeup that includes dark lipstick and eye makeup. Her hairstyle is a short, blonde bob.\"\n",
    "#prompt = \"The person is dressed in a suit and tie, with a pink shirt and a blue blazer. The fashion style can be described as formal or business casual.\"\n",
    "#prompt = \"The image features a person who appears to be a woman. She has blonde hair and is wearing makeup that includes dark lipstick.\"\n",
    "prompt = \"The person is wearing a bright orange dress. The fashion style of the person can be described as summery and vibrant, with a focus on bold colors and light fabrics.\"\n",
    "#prompt = \"The scene is set in a room with a vintage or classic aesthetic. In the background, there are framed pictures on the wall, including one that appears to be a painting of a nude woman. The model is posing in front of the wall, standing between two chairs with a relaxed yet poised posture. He is looking directly at the camera, which suggests a confident and polished demeanor.\"\n",
    "#prompt = \"The scene is set against a white brick wall with a decorative element that resembles a heart shape. The model is posing on a stool, sitting with one leg crossed over the other, and holding the bag in his lap. He is looking directly at the camera with a neutral expression. The overall fashion style of the image suggests a casual yet stylish look, possibly for a brand that focuses on leather accessories and casual outerwear.\"\n",
    "#prompt = \"The scene is set against a white brick wall with a decorative element that resembles a heart shape. The model is posing on a stool, sitting with one leg crossed over the other, and holding the bag in his lap.\"\n",
    "#prompt = \"The scene takes place in a room with orange walls, which complements the person's outfit. The person is sitting on a large, round, orange cushion or ottoman, which is placed against the wall. She is posing in a relaxed manner, with one leg crossed over the other, and her hands resting on her knees. The person's pose and the choice of the orange background create a cohesive and visually appealing image that highlights the clothing and the color scheme.\"\n",
    "#prompt = \"The image features a person who appears to be a young adult female. She has dark skin and her hair is styled in a way that it falls over her shoulders.\"\n",
    "#prompt = \"Maya is a spirited graphic designer in her late twenties, with a penchant for bold colors and unconventional ideas. She’s always sketching concepts in her notebook, humming softly as she works. Curious and empathetic, Maya thrives on collaboration, but she values her quiet moments with coffee and a good book, finding inspiration in the smallest details of life.\"\n",
    "#prompt = \"David is a middle-aged history professor with a calm demeanor and sharp intellect. His salt-and-pepper hair frames a face lined from years of laughter and thoughtful contemplation. Passionate about ancient civilizations, he captivates students with stories of the past. Outside the classroom, he enjoys gardening, jazz music, and long evening walks through the city streets.\"\n",
    "prompt_length = len(prompt.split(\" \"))\n",
    "target_tokens = prompt_length//2\n",
    "final_prompt_1 = f'Summarize this person comprehensively into {target_tokens} tokens \"' + prompt + '\"'\n",
    "min_tokens = target_tokens - 15\n",
    "max_tokens = target_tokens + 15\n",
    "print(final_prompt_1)\n",
    "\n",
    "# First summarization \n",
    "summparams = SummParams(\n",
    "    text = final_prompt_1,\n",
    "    tokenizer = tokenizer,\n",
    "    model = model,\n",
    "    num_beams = 2,\n",
    "    max_input_length = 1024,\n",
    "    min_output_length = max(16, min_tokens),\n",
    "    max_output_length= min(max_tokens, int(0.8*prompt_length)),\n",
    "    device = device\n",
    ")\n",
    "\n",
    "summarized_text_1 = summarize_text(summparams)\n",
    "print(summarized_text_1)\n",
    "print(len(summarized_text_1.split(\" \")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77f65b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scene takes place in a room with orange walls, which complements the person's outfit. The person is sitting on a large, round, orange cushion or ottoman, which is placed against the wall.\n"
     ]
    }
   ],
   "source": [
    "inputs = summparams.tokenizer([summparams.text], max_length=summparams.max_input_length, return_tensors='pt').to(summparams.device)\n",
    "summary_ids = summparams.model.generate(inputs['input_ids'], num_beams=summparams.num_beams, min_length=summparams.min_output_length, max_length=summparams.max_output_length, early_stopping=True, repetition_penalty=2.0)\n",
    "summarized_text =  (summparams.tokenizer.decode(summary_ids[0], skip_special_tokens=True, truncation=True))\n",
    "print(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97470dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# //2 +-10\n",
    "relationships = [ #(yes/no/failed), prompt_length, prompt_length//2, min_output, max_output\n",
    "    [\"yes\", 78, 39, 29, 49],\n",
    "    [\"yes\", 30, 15, 5, 25],\n",
    "    [\"yes\", 31, 15, 5, 25],\n",
    "    [\"yes\", 76, 38, 48, 28],\n",
    "    [\"yes\", 40, 29, 10, 30],\n",
    "    [\"yes\", 42, 21, 11, 31],\n",
    "    [\"yes\", 54, 27, 17, 37],\n",
    "    [\"yes\", 28, 14, 4, 24]\n",
    "]\n",
    "\n",
    "# //2 +-10 with max(16, min) and min(36, max) --> YEEFUCKINGHAWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
    "relationships_2 = [\n",
    "    [\"no\", 78, 39, 29, 49],\n",
    "    [\"no\", 68, 34, 44, 24]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a14e68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18*1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "dbd51b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_length//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ea5bdb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 1 (length: 11): The model is wearing a brown leather jacket and black pants.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Summary 1 (length: {len(summarized_text_1.split(\" \"))}): {summarized_text_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1fec1c",
   "metadata": {},
   "source": [
    "## GEMMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c7547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16db76e0f1584b27b207fd2aa4f8fa87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=credentials.hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc7a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9d59e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model directly\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6f62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc9b8a4789d4d45ac0d7500f374fc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,             # or False if you want full precision\n",
    "    bnb_4bit_quant_type=\"nf4\",     # 'nf4' or 'fp4'\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # can also try torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf69b063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a240753",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Summarize this text into about 55 words: \"The image features a person who appears to be a woman. She has dark skin and is wearing her hair in an updo.The person is wearing a long, oversized coat that reaches down to her ankles. The coat has a high collar and appears to be made of a heavy fabric, suggesting a fashion style that is both functional and fashionable.The scene is set against a white brick wall with a decorative element that resembles a heart shape. The model is posing on a stool, sitting with one leg crossed over the other, and holding the bag in his lap. He is looking directly at the camera with a neutral expression. The overall fashion style of the image suggests a casual yet stylish look, possibly for a brand that focuses on leather accessories and casual outerwear.\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eb45d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['polo.jpg', 'outdoor.jpg', 'dior.png']\n",
      "Final prompt (length: 129): The image features a person who appears to be a young woman with long blonde hair. She has a fair complexion and is wearing makeup that includes lipstick and eye makeup.The person is wearing a bright orange dress. The fashion style of the person can be described as summery and vibrant, with a focus on bold colors and light fabrics.The scene is set against a dark gray background. The person is posing in a dynamic manner, with one leg lifted and the other bent at the knee, giving the impression of movement. The person is holding a small, colorful clutch in their right hand, which is raised slightly above their hip. The pose and the way the person is holding the clutch suggest a sense of elegance and style.\n",
      "Summarize this text into about 55 words: \"The image features a person who appears to be a young woman with long blonde hair. She has a fair complexion and is wearing makeup that includes lipstick and eye makeup.The person is wearing a bright orange dress. The fashion style of the person can be described as summery and vibrant, with a focus on bold colors and light fabrics.The scene is set against a dark gray background. The person is posing in a dynamic manner, with one leg lifted and the other bent at the knee, giving the impression of movement. The person is holding a small, colorful clutch in their right hand, which is raised slightly above their hip. The pose and the way the person is holding the clutch suggest a sense of elegance and style.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = generate_random_prompt(images_dict)\n",
    "prompt = 'Summarize this text into about 55 words: \"' + prompt + '\"'\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1fe58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "361acf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2753416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with blonde hair and fair skin wears a vibrant orange dress against a dark gray background.  She poses dynamically, one leg lifted and the other bent, holding a colorful clutch.  The fashion is summery and bold, showcasing a sense of elegance and style. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "\tmessages,\n",
    "\tadd_generation_prompt=True,\n",
    "\ttokenize=True,\n",
    "\treturn_dict=True,\n",
    "\treturn_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "summary = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "275a4e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ec799",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bannerg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
