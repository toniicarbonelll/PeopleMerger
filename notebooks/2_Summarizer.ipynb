{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5050c696",
   "metadata": {},
   "source": [
    "**SUMMARIZER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919eef3",
   "metadata": {},
   "source": [
    "In this notebook we will be trying GEMMA to summarize our long prompts into something that would fit FLUX (so maximum of 77 tokens or circa 55 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739cba2",
   "metadata": {},
   "source": [
    "# 0. Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7378e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "from credentials import Credentials\n",
    "credentials = Credentials()\n",
    "os.environ[\"http_proxy\"] = credentials.http_proxy\n",
    "os.environ[\"https_proxy\"] = credentials.https_proxy\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4288eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_dict(images_dict_path:str)->dict:\n",
    "    \"\"\"Loads images dictionary from the path\n",
    "\n",
    "    Args:\n",
    "        images_dict_path (str): Path to images dictionary\n",
    "\n",
    "    Returns:\n",
    "        dict: Images dictionary\n",
    "    \"\"\"\n",
    "    with open(images_dict_path, 'rb') as fp:\n",
    "        images_dict = pickle.load(fp)\n",
    "    return images_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ae42a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dict = load_images_dict('images_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d775747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_prompt(images_dict: dict)->str:\n",
    "    \"\"\"Generates a prompt from the images dictionary by combining three random elements \n",
    "\n",
    "    Args:\n",
    "        images_dict (dict): Images dictionary\n",
    "\n",
    "    Returns:\n",
    "        str: Generated prompt\n",
    "    \"\"\"\n",
    "    #choosing three random elements\n",
    "    keys = list(images_dict.keys()) \n",
    "    chosen_keys = [str(string) for string in np.random.choice(keys, 3, replace=False)] \n",
    "    print(chosen_keys)\n",
    "\n",
    "    #building the prompt\n",
    "    prompt = images_dict[chosen_keys[0]]['person']\n",
    "    prompt += images_dict[chosen_keys[1]]['clothes']\n",
    "    prompt += images_dict[chosen_keys[2]]['scenario']\n",
    "    print(f\"Final prompt (length: {len(prompt.split(\" \"))}): {prompt}\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa2ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['polo2.jpg', 'orange.jpg', 'street.jpg']\n",
      "Final prompt (length: 125): The image features a person who appears to be a young adult male. He has short, light-colored hair and is wearing glasses.The person is wearing a bright orange hoodie and matching orange socks. Her fashion style can be described as casual and sporty, with a focus on bold, vibrant colors.The scene is set on a city street, with a building featuring a window and a street sign in the background. The person is standing on the sidewalk, posing with one hand on her hip and the other hand resting on her thigh. She is looking directly at the camera, which gives the impression that she is the focal point of the image. The pose and the setting suggest a sense of urban style and confidence.\n"
     ]
    }
   ],
   "source": [
    "random_prompt = generate_random_prompt(images_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1fec1c",
   "metadata": {},
   "source": [
    "## 1. GEMMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "805c7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=credentials.hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc7a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6f62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc9b8a4789d4d45ac0d7500f374fc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,             # or False if you want full precision\n",
    "    bnb_4bit_quant_type=\"nf4\",     # 'nf4' or 'fp4'\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # can also try torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf69b063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a240753",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Summarize this text into about 55 words: \"The image features a person who appears to be a woman. She has dark skin and is wearing her hair in an updo.The person is wearing a long, oversized coat that reaches down to her ankles. The coat has a high collar and appears to be made of a heavy fabric, suggesting a fashion style that is both functional and fashionable.The scene is set against a white brick wall with a decorative element that resembles a heart shape. The model is posing on a stool, sitting with one leg crossed over the other, and holding the bag in his lap. He is looking directly at the camera with a neutral expression. The overall fashion style of the image suggests a casual yet stylish look, possibly for a brand that focuses on leather accessories and casual outerwear.\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eb45d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['polo.jpg', 'outdoor.jpg', 'dior.png']\n",
      "Final prompt (length: 129): The image features a person who appears to be a young woman with long blonde hair. She has a fair complexion and is wearing makeup that includes lipstick and eye makeup.The person is wearing a bright orange dress. The fashion style of the person can be described as summery and vibrant, with a focus on bold colors and light fabrics.The scene is set against a dark gray background. The person is posing in a dynamic manner, with one leg lifted and the other bent at the knee, giving the impression of movement. The person is holding a small, colorful clutch in their right hand, which is raised slightly above their hip. The pose and the way the person is holding the clutch suggest a sense of elegance and style.\n",
      "Summarize this text into about 55 words: \"The image features a person who appears to be a young woman with long blonde hair. She has a fair complexion and is wearing makeup that includes lipstick and eye makeup.The person is wearing a bright orange dress. The fashion style of the person can be described as summery and vibrant, with a focus on bold colors and light fabrics.The scene is set against a dark gray background. The person is posing in a dynamic manner, with one leg lifted and the other bent at the knee, giving the impression of movement. The person is holding a small, colorful clutch in their right hand, which is raised slightly above their hip. The pose and the way the person is holding the clutch suggest a sense of elegance and style.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = generate_random_prompt(images_dict)\n",
    "prompt = 'Summarize this text into about 55 words: \"' + prompt + '\"'\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1fe58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2753416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with blonde hair and fair skin wears a vibrant orange dress against a dark gray background.  She poses dynamically, one leg lifted and the other bent, holding a colorful clutch.  The fashion is summery and bold, showcasing a sense of elegance and style. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "\tmessages,\n",
    "\tadd_generation_prompt=True,\n",
    "\ttokenize=True,\n",
    "\treturn_dict=True,\n",
    "\treturn_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "summary = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "275a4e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary.split(\" \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bannerg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
